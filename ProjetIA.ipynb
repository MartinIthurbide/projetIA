{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "986e691b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pa\n",
    "letters_train = pa.read_csv(\n",
    "    'https://www.labri.fr/perso/zemmari/datasets/emnist/emnist-letters-train.csv',\n",
    "    header=None)\n",
    "letters_test = pa.read_csv(\n",
    "    'https://www.labri.fr/perso/zemmari/datasets/emnist/emnist-letters-test.csv',\n",
    "    header=None)\n",
    "def load_letters():\n",
    "    X_train = np.array(letters_train.iloc[:, 1:785])\n",
    "    y_train = np.array(letters_train.iloc[:, 0])\n",
    "    y_train = y_train - 1\n",
    "    X_test = np.array(letters_test.iloc[:, 1:785])\n",
    "    y_test = np.array(letters_test.iloc[:, 0])\n",
    "    y_test = y_test -1 \n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], 28, 28))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], 28, 28))\n",
    "    return (X_train, y_train), (X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd7d8b8",
   "metadata": {},
   "source": [
    "# Partie 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a8227f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25]\n",
      "X_train shape: (88800, 28, 28, 1)\n",
      "y_train shape: (88800, 26)\n",
      "X_test shape: (14800, 28, 28, 1)\n",
      "y_test shape: (14800, 26)\n"
     ]
    }
   ],
   "source": [
    "# Question 1\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "(X_train, y_train), (X_test, y_test) = load_letters()\n",
    "img_rows, img_cols = X_train.shape[1], X_train.shape[2]\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train  = X_train / 255\n",
    "X_test  = X_test / 255\n",
    "\n",
    "unique_classes = np.unique(y_train)\n",
    "print(unique_classes)\n",
    "\n",
    "num_classes = unique_classes.size\n",
    "\n",
    "\n",
    "y_train = to_categorical(y_train,num_classes)\n",
    "y_test = to_categorical(y_test,num_classes)\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be9747bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1600)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               204928    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 26)                3354      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 227,098\n",
      "Trainable params: 227,098\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\verca\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\verca\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\verca\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\verca\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1024, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\verca\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1082, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Users\\verca\\anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\verca\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 152, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\verca\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 284, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\verca\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 2004, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"C:\\Users\\verca\\anaconda3\\lib\\site-packages\\keras\\backend.py\", line 5532, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (100, 2) and (100, 26) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_53576\\4230385068.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mletter_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Total accuracy:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                     \u001b[0mretval_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m                 \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\verca\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\verca\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\verca\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\verca\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1024, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\verca\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1082, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Users\\verca\\anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\verca\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 152, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\verca\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 284, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\verca\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 2004, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"C:\\Users\\verca\\anaconda3\\lib\\site-packages\\keras\\backend.py\", line 5532, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (100, 2) and (100, 26) are incompatible\n"
     ]
    }
   ],
   "source": [
    "# Question 2\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "def letter_network():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(26, activation='softmax')) #26 lettres dans l'alphabet\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "model = letter_network()\n",
    "model.summary()\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=100, validation_data=(X_test, y_test))\n",
    "scores = model.evaluate(X_test, y_test)\n",
    "print(\"Total accuracy:\", scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2debfdef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_7 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 13, 13, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 5, 5, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 3, 3, 128)         73856     \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 1, 1, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 26)                3354      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 112,538\n",
      "Trainable params: 112,538\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "888/888 [==============================] - 63s 70ms/step - loss: 0.8824 - accuracy: 0.7223 - val_loss: 0.6086 - val_accuracy: 0.7875\n",
      "Epoch 2/10\n",
      "888/888 [==============================] - 58s 66ms/step - loss: 0.4402 - accuracy: 0.8527 - val_loss: 0.4315 - val_accuracy: 0.8542\n",
      "Epoch 3/10\n",
      "888/888 [==============================] - 59s 66ms/step - loss: 0.3576 - accuracy: 0.8783 - val_loss: 0.3985 - val_accuracy: 0.8644\n",
      "Epoch 4/10\n",
      "888/888 [==============================] - 59s 67ms/step - loss: 0.3097 - accuracy: 0.8944 - val_loss: 0.3672 - val_accuracy: 0.8739\n",
      "Epoch 5/10\n",
      "888/888 [==============================] - 65s 73ms/step - loss: 0.2814 - accuracy: 0.9033 - val_loss: 0.3567 - val_accuracy: 0.8805\n",
      "Epoch 6/10\n",
      "888/888 [==============================] - 69s 78ms/step - loss: 0.2564 - accuracy: 0.9103 - val_loss: 0.3529 - val_accuracy: 0.8764\n",
      "Epoch 7/10\n",
      "888/888 [==============================] - 63s 70ms/step - loss: 0.2358 - accuracy: 0.9170 - val_loss: 0.3435 - val_accuracy: 0.8826\n",
      "Epoch 8/10\n",
      "888/888 [==============================] - 67s 75ms/step - loss: 0.2192 - accuracy: 0.9212 - val_loss: 0.3329 - val_accuracy: 0.8861\n",
      "Epoch 9/10\n",
      "888/888 [==============================] - 64s 72ms/step - loss: 0.1997 - accuracy: 0.9273 - val_loss: 0.3323 - val_accuracy: 0.8893\n",
      "Epoch 10/10\n",
      "888/888 [==============================] - 63s 71ms/step - loss: 0.1902 - accuracy: 0.9304 - val_loss: 0.3455 - val_accuracy: 0.8872\n",
      "463/463 [==============================] - 3s 7ms/step - loss: 0.3455 - accuracy: 0.8872\n",
      "Total accuracy: 0.8871621489524841\n"
     ]
    }
   ],
   "source": [
    "def letter_network_2():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(26, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = letter_network_2()\n",
    "model.summary()\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=100, validation_data=(X_test, y_test))\n",
    "scores = model.evaluate(X_test, y_test)\n",
    "print(\"Total accuracy:\", scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a830ae1",
   "metadata": {},
   "source": [
    "On voit que dans ce réseau où nous avons rajoutés une couche Conv2D supplémentaire, le total accuracy est plus faible que celui avec seulement 2 couches Conv2D. Ce qui prouve qu'il y a eu un surapprentissage et donc que l'accuracy est plus faible. Donc trop de couches par rapport aux données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0abc9e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def letter_network_dropout():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.25)) # dropout\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.25)) # dropout\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5)) # dropout\n",
    "    model.add(Dense(26, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a0807a",
   "metadata": {},
   "source": [
    "Dans ce réseau, nous avons rajouté le Dropout qui permet de mettre aléatoirement certains poids du modèle à zéro pendant l'entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af23313e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_5 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 13, 13, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 13, 13, 32)        0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 5, 5, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 5, 5, 64)          0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 1600)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               204928    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 26)                3354      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 227,098\n",
      "Trainable params: 227,098\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "888/888 [==============================] - 69s 76ms/step - loss: 1.0333 - accuracy: 0.6829 - val_loss: 0.4063 - val_accuracy: 0.8682\n",
      "Epoch 2/10\n",
      "888/888 [==============================] - 72s 81ms/step - loss: 0.5539 - accuracy: 0.8245 - val_loss: 0.3314 - val_accuracy: 0.8891\n",
      "Epoch 3/10\n",
      "888/888 [==============================] - 69s 77ms/step - loss: 0.4678 - accuracy: 0.8508 - val_loss: 0.2878 - val_accuracy: 0.9035\n",
      "Epoch 4/10\n",
      "888/888 [==============================] - 65s 73ms/step - loss: 0.4171 - accuracy: 0.8675 - val_loss: 0.2785 - val_accuracy: 0.9056\n",
      "Epoch 5/10\n",
      "888/888 [==============================] - 65s 73ms/step - loss: 0.3872 - accuracy: 0.8757 - val_loss: 0.2643 - val_accuracy: 0.9089\n",
      "Epoch 6/10\n",
      "888/888 [==============================] - 68s 77ms/step - loss: 0.3595 - accuracy: 0.8831 - val_loss: 0.2594 - val_accuracy: 0.9118\n",
      "Epoch 7/10\n",
      "888/888 [==============================] - 64s 72ms/step - loss: 0.3414 - accuracy: 0.8903 - val_loss: 0.2403 - val_accuracy: 0.9185\n",
      "Epoch 8/10\n",
      "888/888 [==============================] - 75s 85ms/step - loss: 0.3238 - accuracy: 0.8944 - val_loss: 0.2394 - val_accuracy: 0.9191\n",
      "Epoch 9/10\n",
      "888/888 [==============================] - 68s 77ms/step - loss: 0.3127 - accuracy: 0.8968 - val_loss: 0.2377 - val_accuracy: 0.9201\n",
      "Epoch 10/10\n",
      "888/888 [==============================] - 62s 70ms/step - loss: 0.3015 - accuracy: 0.9005 - val_loss: 0.2346 - val_accuracy: 0.9196\n",
      "463/463 [==============================] - 4s 8ms/step - loss: 0.2346 - accuracy: 0.9196\n",
      "Total accuracy: 0.9195945858955383\n"
     ]
    }
   ],
   "source": [
    "model = letter_network_dropout()\n",
    "model.summary()\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=100, validation_data=(X_test, y_test))\n",
    "scores = model.evaluate(X_test, y_test)\n",
    "print(\"Total accuracy:\", scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68001861",
   "metadata": {},
   "source": [
    "On voit donc qu'avec le modèle letter_network, on a pour chaque epoch une meilleure accuracy que sur letter_network_dropout. Mais par contre on a un moins bon total accuracy que sur letter_network_dropout car le réseau a appris des détails des données inutiles et donc sur chaque entrainement a eu un meilleur accuracy.\n",
    "\n",
    "Sauf que au total on se retrouve avec une accuracy de 91.8% contre 92% avec le dropout. Signe que Dropout aide à prévenir le surapprentissage.\n",
    "\n",
    "On peut tester une autre structure en utilisant un autre optimizer que \"adam\", mais dans notre cas cela ne change pas grand chose ou du moins cela n'améliore pas notre accuracy lors de l'entrainement de notre modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a390205",
   "metadata": {},
   "source": [
    "# Partie 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb9aaf2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (148800, 28, 28, 1)\n",
      "y_train shape: (148800, 2)\n",
      "X_test shape: (24800, 28, 28, 1)\n",
      "y_test shape: (24800, 2)\n"
     ]
    }
   ],
   "source": [
    "# Question 1\n",
    "from keras.datasets import mnist\n",
    "import random\n",
    "# load des lettres\n",
    "(X_train_letters, y_train_letters), (X_test_letters, y_test_letters) = load_letters()\n",
    "\n",
    "for i in range(y_train_letters.size):\n",
    "    y_train_letters[i] = 0\n",
    "\n",
    "for i in range(y_test_letters.size):\n",
    "    y_test_letters[i] = 0\n",
    "\n",
    "# load des chiffres\n",
    "(X_train_numbers, y_train_numbers), (X_test_numbers, y_test_numbers) = mnist.load_data()\n",
    "\n",
    "for i in range(y_train_numbers.size):\n",
    "    y_train_numbers[i] = 1\n",
    "\n",
    "for i in range(y_test_numbers.size):\n",
    "    y_test_numbers[i] = 1\n",
    "\n",
    "# on concatene les données\n",
    "X_train = np.concatenate((X_train_letters,X_train_numbers))\n",
    "y_train = np.concatenate((y_train_letters,y_train_numbers))\n",
    "\n",
    "X_test = np.concatenate((X_test_letters,X_test_numbers))\n",
    "y_test = np.concatenate((y_test_letters,y_test_numbers))\n",
    "\n",
    "# on definit la taille\n",
    "img_rows, img_cols = X_train.shape[1], X_train.shape[2]\n",
    "\n",
    "# On reshape en 1D\n",
    "X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "\n",
    "# on transforme y_train et y_test en vecteurs\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ceb19b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_5 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 128)               100480    \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 100,738\n",
      "Trainable params: 100,738\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "1488/1488 [==============================] - 11s 6ms/step - loss: 0.2719 - accuracy: 0.9789 - val_loss: 0.0302 - val_accuracy: 0.9927\n",
      "Epoch 2/5\n",
      "1488/1488 [==============================] - 7s 5ms/step - loss: 0.0222 - accuracy: 0.9931 - val_loss: 0.0242 - val_accuracy: 0.9929\n",
      "Epoch 3/5\n",
      "1488/1488 [==============================] - 7s 5ms/step - loss: 0.0188 - accuracy: 0.9942 - val_loss: 0.0317 - val_accuracy: 0.9923\n",
      "Epoch 4/5\n",
      "1488/1488 [==============================] - 8s 6ms/step - loss: 0.0218 - accuracy: 0.9937 - val_loss: 0.0245 - val_accuracy: 0.9924\n",
      "Epoch 5/5\n",
      "1488/1488 [==============================] - 10s 7ms/step - loss: 0.0206 - accuracy: 0.9942 - val_loss: 0.0135 - val_accuracy: 0.9963\n",
      "775/775 [==============================] - 3s 3ms/step - loss: 0.0135 - accuracy: 0.9963\n",
      "Total accuracy: 0.9962903261184692\n"
     ]
    }
   ],
   "source": [
    "def neural_network0():\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=(28, 28, 1)))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(2, kernel_initializer='normal', activation='softmax'))    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = neural_network0()\n",
    "model.summary()\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=5,batch_size=100)\n",
    "scores = model.evaluate(X_test, y_test)\n",
    "print(\"Total accuracy:\", scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ac2cbd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_12 (Conv2D)          (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPoolin  (None, 13, 13, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPoolin  (None, 5, 5, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 1600)              0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 128)               204928    \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 224,002\n",
      "Trainable params: 224,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "1488/1488 [==============================] - 107s 69ms/step - loss: 0.2493 - accuracy: 0.9841 - val_loss: 0.0052 - val_accuracy: 0.9983\n",
      "Epoch 2/5\n",
      "1488/1488 [==============================] - 97s 65ms/step - loss: 0.0054 - accuracy: 0.9982 - val_loss: 0.0047 - val_accuracy: 0.9986\n",
      "Epoch 3/5\n",
      "1488/1488 [==============================] - 92s 62ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.0036 - val_accuracy: 0.9987\n",
      "Epoch 4/5\n",
      "1488/1488 [==============================] - 95s 64ms/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 0.0015 - val_accuracy: 0.9994\n",
      "Epoch 5/5\n",
      "1488/1488 [==============================] - 98s 66ms/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 0.0016 - val_accuracy: 0.9996\n",
      "775/775 [==============================] - 5s 7ms/step - loss: 0.0016 - accuracy: 0.9996\n",
      "Total accuracy: 0.9995564222335815\n"
     ]
    }
   ],
   "source": [
    "def neural_network_cnn():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32,kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "    model.add(MaxPooling2D((2,2)))\n",
    "    model.add(Conv2D(64,kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = neural_network_cnn()\n",
    "model.summary()\n",
    "history = model.fit(X_train, y_train, epochs=5, batch_size=100, validation_data=(X_test, y_test))\n",
    "scores = model.evaluate(X_test, y_test)\n",
    "print(\"Total accuracy:\", scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b30ff36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ef82184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 13, 13, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 5, 5, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 3, 3, 128)         73856     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 1, 1, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,442\n",
      "Trainable params: 109,442\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "1488/1488 [==============================] - 52s 33ms/step - loss: 0.1094 - accuracy: 0.9749 - val_loss: 0.0155 - val_accuracy: 0.9952\n",
      "Epoch 2/5\n",
      "1488/1488 [==============================] - 49s 33ms/step - loss: 0.0149 - accuracy: 0.9952 - val_loss: 0.0182 - val_accuracy: 0.9940\n",
      "Epoch 3/5\n",
      "1488/1488 [==============================] - 50s 33ms/step - loss: 0.0106 - accuracy: 0.9965 - val_loss: 0.0122 - val_accuracy: 0.9966\n",
      "Epoch 4/5\n",
      "1488/1488 [==============================] - 49s 33ms/step - loss: 0.0073 - accuracy: 0.9976 - val_loss: 0.0040 - val_accuracy: 0.9984\n",
      "Epoch 5/5\n",
      "1488/1488 [==============================] - 49s 33ms/step - loss: 0.0064 - accuracy: 0.9978 - val_loss: 0.0089 - val_accuracy: 0.9976\n",
      "775/775 [==============================] - 4s 5ms/step - loss: 0.0089 - accuracy: 0.9976\n",
      "Total accuracy: 0.9976209402084351\n"
     ]
    }
   ],
   "source": [
    "def neural_network_deep_cnn():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32,kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "    model.add(MaxPooling2D((2,2)))\n",
    "    model.add(Conv2D(64,kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(128,kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = neural_network_deep_cnn()\n",
    "model.summary()\n",
    "history = model.fit(X_train, y_train, epochs=5, batch_size=100, validation_data=(X_test, y_test))\n",
    "scores = model.evaluate(X_test, y_test)\n",
    "print(\"Total accuracy:\", scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c8775c",
   "metadata": {},
   "source": [
    "Pour cette partie nous avons choisi 3 architectures différentes, une neutre, une CNN classique et une CNN profonde.\n",
    "\n",
    "Dans chacune des 3 architectures nous finissons par une couche Dense avec 2 neuronnes afin de représenter les 2 catégories que nous cherchons à distinguer (vetements et accesoires).\n",
    "\n",
    "Nous avons choisi de faire un réseau neutre pour commencer étant donné que ce n'est pas le type d'architecture le plus adapté pour notre sujet nous ne nous attendions pas d'aussi bons résultats que les deux architectures suivantes. Elle est très rapide et a un modéle très court ce qui la rend pratique mais cependant la précision s'en voit réduite dans cette application.\n",
    "\n",
    "En effet, CNN est bien plus adapté pour la reconaissance d'image nous avons donc fait deux version, une n'allant pas très loin dans l'apprentissage et l'autre plus. C'est à dire que la non profonde s'arrete à un Conv2D de 64 alors que dans la profonde nous avons ajouté une couche en plus jusqu'à 128.\n",
    "Le risque étant que cela provoque un surapprentissage a cause de l'architecture plus profonde et cela peut provoquer une baisse de la précision.\n",
    "Ce qui est exactement le comportement qu'on a pu observer lors de nos tests.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
